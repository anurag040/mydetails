from flask import Flask, request, jsonify, render_template, send_file
import pandas as pd
import os
import nltk
from collections import Counter

# Initialize Flask app
app = Flask(__name__)

# Ensure necessary downloads
nltk.download('punkt')

# Load and preprocess the corpus
try:
    corpus_df = pd.read_csv('alldata_1_for_kaggle.csv', encoding='ISO-8859-1')
    corpus_text = " ".join(corpus_df['Research Paper Text'].dropna().tolist())
except Exception as e:
    raise RuntimeError("Failed to load or process the corpus. Ensure the file is available and properly formatted.") from e

# Tokenize the corpus and build a frequency dictionary
corpus_words = nltk.word_tokenize(corpus_text.lower())
word_freq = Counter(corpus_words)

# Define word correction utilities
def known(words):
    """Return the subset of `words` that are in the corpus."""
    return {w for w in words if w in word_freq}

def edits1(word):
    """Generate all edits that are one edit away from `word`."""
    letters = 'abcdefghijklmnopqrstuvwxyz'
    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]
    deletes = [L + R[1:] for L, R in splits if R]
    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]
    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]
    inserts = [L + c + R for L, R in splits for c in letters]
    return set(deletes + transposes + replaces + inserts)

def edits2(word):
    """Generate all edits that are two edits away from `word`."""
    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}

def correct(word):
    """Find the most probable correction for `word`."""
    candidates = known([word]) or known(edits1(word)) or known(edits2(word)) or [word]
    return max(candidates, key=word_freq.get)

# Flask routes
@app.route('/')
def home():
    return render_template('index.html')

@app.route('/correct_word', methods=['POST'])
def correct_word():
    word = request.json.get('word')
    if not word:
        return jsonify({'error': 'No word provided'}), 400

    corrected_word = correct(word.lower())
    return jsonify({'corrected_word': corrected_word})

@app.route('/upload_file', methods=['POST'])
def upload_file():
    file = request.files.get('file')
    if not file:
        return jsonify({'error': 'No file uploaded'}), 400

    # Save the uploaded file
    file_path = os.path.join('uploads', file.filename)
    file.save(file_path)

    # Process the file content
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read()
    except UnicodeDecodeError:
        with open(file_path, 'r', encoding='ISO-8859-1') as f:
            text = f.read()

    # Correct the text
    corrected_text = " ".join([correct(word.lower()) for word in nltk.word_tokenize(text)])
    corrected_file_path = os.path.join('uploads', f'corrected_{file.filename}')
    with open(corrected_file_path, 'w', encoding='utf-8') as f:
        f.write(corrected_text)

    return send_file(corrected_file_path, as_attachment=True)

if __name__ == '__main__':
    if not os.path.exists('uploads'):
        os.makedirs('uploads')
    app.run(debug=True, host='0.0.0.0', port=5000)
